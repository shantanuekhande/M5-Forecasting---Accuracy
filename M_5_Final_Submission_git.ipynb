{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zTyuh0OtlZG-"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(u'nbAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# !pip install downcast\n",
    "import numpy\n",
    "import time\n",
    "from downcast import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhkSxJJUnYjf",
    "outputId": "af0583b2-2a64-4654-a9d7-22d4fc1adb9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kwg69pGQlZi4"
   },
   "outputs": [],
   "source": [
    "with open(r'/content/drive/MyDrive/Project Files/train_CV_test_data_x_y_id.pkl', 'rb') as f:\n",
    "    x_train,x_CV,x_test,y_train,y_CV,y_test,id= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQetufltlZlj",
    "outputId": "40288770-a3fa-4365-a77d-3e11fb5996e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on LGBM is: 2.003571591469768\n"
     ]
    }
   ],
   "source": [
    "clf=LGBMRegressor(objective ='poisson',learning_rate=0.2,n_estimators=100)\n",
    "clf.fit(x_train,y_train)\n",
    "y_predict=clf.predict(x_test)\n",
    "RMSE=mean_squared_error(y_test, y_predict, squared=False)\n",
    "print('RMSE on LGBM is:',RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ANa2FVglZo5"
   },
   "outputs": [],
   "source": [
    "with open(r'best_LGBM_clf_objective_poision_m5.pkl','wb') as f:\n",
    "    pickle.dump([clf],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZ3EEUl9lZr4"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "# original = r'original path where the file is currently stored\\file name.file extension'\n",
    "# target = r'target path where the file will be copied\\file name.file extension'\n",
    "original=r'/content/best_LGBM_clf_objective_poision_m5.pkl'\n",
    "target=r'/content/drive/MyDrive/Project Files/best_LGBM_clf_objective_poision_m5.pkl'\n",
    "shutil.copyfile(original,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8o-zVZKvkyWU",
    "outputId": "c99dbe44-0e7b-4ce0-be70-dc8636c0004e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
      "Downloading sales_train_validation.csv.zip to train\n",
      " 58% 9.00M/15.5M [00:00<00:00, 20.7MB/s]\n",
      "100% 15.5M/15.5M [00:00<00:00, 31.6MB/s]\n",
      "Downloading sell_prices.csv.zip to train\n",
      " 84% 12.0M/14.2M [00:00<00:00, 33.6MB/s]\n",
      "100% 14.2M/14.2M [00:00<00:00, 47.4MB/s]\n",
      "Downloading sales_train_evaluation.csv.zip to train\n",
      " 69% 11.0M/15.8M [00:00<00:00, 28.1MB/s]\n",
      "100% 15.8M/15.8M [00:00<00:00, 44.9MB/s]\n",
      "Downloading calendar.csv to train\n",
      "  0% 0.00/101k [00:00<?, ?B/s]\n",
      "100% 101k/101k [00:00<00:00, 112MB/s]\n",
      "Downloading sample_submission.csv.zip to train\n",
      "  0% 0.00/163k [00:00<?, ?B/s]\n",
      "100% 163k/163k [00:00<00:00, 156MB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"shantanuekhande\"\n",
    "os.environ['KAGGLE_KEY'] = \"7c0f27a1e48312dc37124571a15b336e\"\n",
    "!kaggle competitions download -c 'm5-forecasting-accuracy'  -p 'train'    ## getting all data into train folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGwgW925vjDB"
   },
   "outputs": [],
   "source": [
    "! mkdir final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwZCwQ1NvEWT",
    "outputId": "cc6df6ae-6313-4edd-8beb-bcbcc9fc5089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs AMD EPYC 7B12 (830F10),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/train/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 16611637 bytes (16 MiB)\n",
      "\n",
      "Extracting archive: /content/train/sales_train_evaluation.csv.zip\n",
      "--\n",
      "Path = /content/train/sales_train_evaluation.csv.zip\n",
      "Type = zip\n",
      "Physical Size = 16611637\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b 35% - sales_train_evaluation.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - sales_train_evaluation.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       121736518\n",
      "Compressed: 16611637\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs AMD EPYC 7B12 (830F10),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/train/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 16297374 bytes (16 MiB)\n",
      "\n",
      "Extracting archive: /content/train/sales_train_validation.csv.zip\n",
      "--\n",
      "Path = /content/train/sales_train_validation.csv.zip\n",
      "Type = zip\n",
      "Physical Size = 16297374\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b 36% - sales_train_validation.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% - sales_train_validation.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       120007726\n",
      "Compressed: 16297374\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs AMD EPYC 7B12 (830F10),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/train/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 166492 bytes (163 KiB)\n",
      "\n",
      "Extracting archive: /content/train/sample_submission.csv.zip\n",
      "--\n",
      "Path = /content/train/sample_submission.csv.zip\n",
      "Type = zip\n",
      "Physical Size = 166492\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       5228786\n",
      "Compressed: 166492\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs AMD EPYC 7B12 (830F10),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/train/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "ERROR: No more files\n",
      "/content/train/calendar.csv.zip\n",
      "\n",
      "\n",
      "\n",
      "System ERROR:\n",
      "Unknown error -2147024872\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs AMD EPYC 7B12 (830F10),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan /content/train/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 14916601 bytes (15 MiB)\n",
      "\n",
      "Extracting archive: /content/train/sell_prices.csv.zip\n",
      "--\n",
      "Path = /content/train/sell_prices.csv.zip\n",
      "Type = zip\n",
      "Physical Size = 14916601\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b 30% - sell_prices.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% - sell_prices.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% - sell_prices.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       203395785\n",
      "Compressed: 14916601\n"
     ]
    }
   ],
   "source": [
    "!7z e /content/train/sales_train_evaluation.csv.zip -o/content/final_train\n",
    "!7z e /content/train/sales_train_validation.csv.zip -o/content/final_train\n",
    "!7z e /content/train/sample_submission.csv.zip -o/content/final_train\n",
    "!7z e /content/train/calendar.csv.zip -o/content/final_train\n",
    "!7z e /content/train/sell_prices.csv.zip -o/content/final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "AKnxkQiorMhJ"
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv(r'/content/final_train/sales_train_evaluation.csv')\n",
    "# sales.name = 'sales'\n",
    "calendar = pd.read_csv(r'/content/train/calendar.csv')\n",
    "# calendar.name = 'calendar'\n",
    "prices = pd.read_csv(r'/content/final_train/sell_prices.csv')\n",
    "# prices.name = 'prices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OEfTDyjZUjLC"
   },
   "outputs": [],
   "source": [
    "# Reducing memory size of DataFrame using Reduce function from downcasting library.\n",
    "# https://medium.com/@deepakec1031/how-to-reduce-pandas-data-frame-size-using-downcast-e00cfed8e2c5\n",
    "sales= reduce(sales)\n",
    "prices= reduce(prices)\n",
    "calendar= reduce(calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MGLJweZwKTU"
   },
   "outputs": [],
   "source": [
    "sales.to_csv('sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2m97K9Njg8va"
   },
   "outputs": [],
   "source": [
    "calendar.to_csv('calendar.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9UXLCU-hAMP",
    "outputId": "194248d3-bdb1-477a-cac5-270dd048862d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6841121 entries, 0 to 6841120\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   store_id    object \n",
      " 1   item_id     object \n",
      " 2   wm_yr_wk    int64  \n",
      " 3   sell_price  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 208.8+ MB\n"
     ]
    }
   ],
   "source": [
    "a=pd.read_csv(r'prices.csv')\n",
    "a.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPlhg-_MwMZZ"
   },
   "source": [
    "### M5 compitation is sales forcasting compitation in which data taken from walmart.in that we have in total 3049 unique product present. so my task is to predict next 28 days sales for any particular product product.so i am writing two function the first function will take the product as input and return next 28 days for that product.(d_1914 to d_1942). the second function will take product and ground truth value as input and return RMSE score as output.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "MfbckG8aySCv"
   },
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "  ## gathering  data into single dataframe  \n",
    "  x=sales[sales['id']==x]\n",
    "  df_sales=pd.melt(x, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold')\n",
    "\n",
    "  # filling NaN values with no_event from calender features (event_name_1,event_type_1,event_name_2,event_type_ )\n",
    "  calendar.fillna('No_event',inplace=True)\n",
    "  df_final= pd.merge(df_sales, calendar, on='d', how='left')\n",
    "  df_final= pd.merge(df_final, prices, on=['store_id','item_id','wm_yr_wk'], how='left') \n",
    "\n",
    "  ## filling NaN value with zero for sell_price column from df_final\n",
    "  df_final.fillna(0,inplace=True)\n",
    "\n",
    "  ## now its time to reduce memory size of df_final dataframe using downcasting technique \n",
    "  df_final=reduce(df_final)\n",
    "\n",
    "\n",
    "  ## now its time to do feature engineering \n",
    "  # 1. Time based feature\n",
    "  # 1.1 Feature name: is_high_sale_months\n",
    "  f=lambda x: 1 if x==2 or x==3 or x==4 or x==5 else 0\n",
    "  df_final['is_high_sale_months']=df_final['month'].map(f) \n",
    "\n",
    "  # 1.2 Feature name: is_high_sale_day\n",
    "  f=lambda x: 1 if x==7 or x==1 or x==2 else 0\n",
    "  df_final['is_high_sale_day']=df_final['wday'].map(f) \n",
    "\n",
    "  # 1.3 Feature name:is_christmas\n",
    "  f=lambda x: 1 if x=='Christmas' else 0\n",
    "  df_final['is_christmas']=df_final['event_name_1'].map(f)\n",
    "\n",
    "  ## 2. Lags\n",
    "  # Feature Name : ['lag_1','lag_7', 'lag_14','lag_21', 'lag_28', 'lag_35', 'lag_42', 'lag_49', 'lag_56', 'lag_63','lag_70']\n",
    "  lags=[1,7,14,21,28,35,42,49,56,63,70]\n",
    "  for i in lags:\n",
    "      df_final['lag_'+str(i)]=df_final.groupby(['id'])['sold'].shift(i)\n",
    "\n",
    "  # if you see in dataframe there is lot of NaN value got created. i am replacing NaN value with \"0\".\n",
    "  lags=['lag_1','lag_7', 'lag_14','lag_21', 'lag_28', 'lag_35', 'lag_42', 'lag_49', 'lag_56', 'lag_63','lag_70']\n",
    "  for i in lags:\n",
    "      df_final[i]=df_final[i].fillna(0)\n",
    "\n",
    "  ## 3. Rolling Window\n",
    "  window=[7,14,21,28,35,42]\n",
    "  for i in  window:\n",
    "      df_final['rolling_mean_'+str(i)]=df_final.groupby(['id'])['sold'].transform(lambda s: s.rolling(i).mean())\n",
    "\n",
    "  # if you see in dataframe there is lot of NaN value got created. i am replacing NaN value with \"0\".\n",
    "  window=['rolling_mean_7','rolling_mean_14','rolling_mean_21','rolling_mean_28', 'rolling_mean_35','rolling_mean_42']\n",
    "  for i in window:\n",
    "      df_final[i]=df_final[i].fillna(0)\n",
    "\n",
    "  ## 4. Expanding Window\n",
    "  df_final['expanding_mean']=df_final.groupby(['id'])['sold'].transform(lambda s: s.expanding().mean())\n",
    "\n",
    "  # if you see in dataframe there is lot of NaN value got created. i am replacing NaN value with \"0\".\n",
    "  df_final['expanding_mean']=df_final['expanding_mean'].fillna(0)\n",
    "\n",
    "  ## 5. Label Encoding:in this we are going to convert categorical variable into numeric using sklearn preprocessing library called LabelEncoder\n",
    "  labelencoder=LabelEncoder() \n",
    "  category=['event_name_1','event_type_1','event_name_2','event_type_2','item_id','dept_id','cat_id','store_id','state_id']\n",
    "  for i in category:\n",
    "      df_final[i+'_']=labelencoder.fit_transform(df_final[i])\n",
    "\n",
    "  # droping duplicate fetures \n",
    "  df_final=df_final.drop(['event_name_1','event_type_1','event_name_2','event_type_2','item_id','dept_id','cat_id','store_id','state_id'],axis = 1)\n",
    "\n",
    "  # removing hypen from \"d\" features : d_1-----> 1, d_100----->100\n",
    "  l=[]\n",
    "  for i in df_final['d']:\n",
    "      l.append(i.split('_')[1])\n",
    "  df_final['day']=l\n",
    "  df_final['day']=df_final['day'].astype(np.int16)\n",
    "\n",
    "\n",
    "  # dropping unusefull feature\n",
    "  df_final=df_final.drop(['event_name_1_','event_name_2_','item_id_','d','date','wm_yr_wk','weekday','year'],axis = 1)\n",
    "  \n",
    "\n",
    "\n",
    "  ## storing id\n",
    "  id=df_final[['id','day']]\n",
    "\n",
    "  ## now dividing data into input and output form\n",
    "  x=df_final.drop(columns=['id','sold'])\n",
    "  y=df_final[['day','sold']]\n",
    "\n",
    "  x_test=x.loc[x['day']>=1914]\n",
    "  x_test=x_test.drop(columns=['day'])\n",
    "\n",
    "  y_test=y.loc[y['day']>=1914]\n",
    "  y_test=y_test.drop(columns=['day'])\n",
    "\n",
    "  ## applying LGBM regressor \n",
    "  # with open(r'/content/drive/MyDrive/Project Files/best_LGBM_clf_objective_poision_m5.pkl', 'rb') as f:\n",
    "  #   clf= pickle.load(f)\n",
    "  y_predicted=clf[0].predict(x_test)\n",
    "\n",
    "  ## converting data into submission format \n",
    "  predicted_=pd.DataFrame({'sold_predicted':y_predicted})\n",
    "  predicted_=predicted_.apply(lambda x :round(x))\n",
    "  predicted_= predicted_['sold_predicted'].astype('int16')\n",
    "  \n",
    "  id_index=id.reset_index()\n",
    "  id_index.drop(columns='index',inplace=True)\n",
    "\n",
    "\n",
    "  final_format=pd.merge(id_index, predicted_, left_index=True, right_index=True)\n",
    "  final_format.pivot(index=['id'], columns='day')\n",
    "\n",
    "\n",
    "  final_LGBM= final_format.pivot(index='id', columns='day')['sold_predicted'].reset_index()\n",
    "  final_LGBM.columns.name = None\n",
    "\n",
    "\n",
    "  return(final_LGBM,y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "rG3ZB3kQWvtY"
   },
   "outputs": [],
   "source": [
    "def function_2(y_test,y_predicted):\n",
    "  ## calculating RMSE \n",
    "  RMSE=mean_squared_error(y_test['sold'], y_predicted, squared=True)\n",
    "  print('RMSE using LGBMRegressor:',RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "X-Be30r69g17",
    "outputId": "ca349cfa-80d3-4d8a-90e6-eaba289b1534"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>d_11</th>\n",
       "      <th>d_12</th>\n",
       "      <th>d_13</th>\n",
       "      <th>d_14</th>\n",
       "      <th>d_15</th>\n",
       "      <th>d_16</th>\n",
       "      <th>d_17</th>\n",
       "      <th>d_18</th>\n",
       "      <th>d_19</th>\n",
       "      <th>d_20</th>\n",
       "      <th>d_21</th>\n",
       "      <th>d_22</th>\n",
       "      <th>d_23</th>\n",
       "      <th>d_24</th>\n",
       "      <th>d_25</th>\n",
       "      <th>d_26</th>\n",
       "      <th>d_27</th>\n",
       "      <th>d_28</th>\n",
       "      <th>d_29</th>\n",
       "      <th>d_30</th>\n",
       "      <th>d_31</th>\n",
       "      <th>d_32</th>\n",
       "      <th>d_33</th>\n",
       "      <th>d_34</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1902</th>\n",
       "      <th>d_1903</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "      <th>d_1914</th>\n",
       "      <th>d_1915</th>\n",
       "      <th>d_1916</th>\n",
       "      <th>d_1917</th>\n",
       "      <th>d_1918</th>\n",
       "      <th>d_1919</th>\n",
       "      <th>d_1920</th>\n",
       "      <th>d_1921</th>\n",
       "      <th>d_1922</th>\n",
       "      <th>d_1923</th>\n",
       "      <th>d_1924</th>\n",
       "      <th>d_1925</th>\n",
       "      <th>d_1926</th>\n",
       "      <th>d_1927</th>\n",
       "      <th>d_1928</th>\n",
       "      <th>d_1929</th>\n",
       "      <th>d_1930</th>\n",
       "      <th>d_1931</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11755</th>\n",
       "      <td>FOODS_3_384_CA_4_evaluation</td>\n",
       "      <td>FOODS_3_384</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id      item_id  ... d_1940 d_1941\n",
       "11755  FOODS_3_384_CA_4_evaluation  FOODS_3_384  ...      0      0\n",
       "\n",
       "[1 rows x 1947 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=sales[sales['id']=='FOODS_3_384_CA_4_evaluation']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "id": "WgxDMQfkV2oy",
    "outputId": "522313eb-4763-4ac0-9245-7fe6b2769a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time required to predict next 28 days sale for one product is : 1.393987999999922\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_3_384_CA_4_evaluation</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  1  2  3  4  5  6  ...  22  23  24  25  26  27  28\n",
       "0  FOODS_3_384_CA_4_evaluation  0  3  0  1  0  0  ...   0   2   4   0   0   0   0\n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start=time.clock() \n",
    "final_LGBM,y_test,y_predicted=function_1('FOODS_3_384_CA_4_evaluation')\n",
    "end=time.clock()\n",
    "total_time=end - start\n",
    "print('total time required to predict next 28 days sale for one product is :',total_time)\n",
    "final_LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfEJjio_YPIS",
    "outputId": "6ff32f1b-9c19-4c9d-feda-a42ad6b4487f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using LGBMRegressor: 1.5081875192553258\n",
      "total time required to RMSE score for one product is : 0.00153499999998985\n"
     ]
    }
   ],
   "source": [
    "start=time.clock() \n",
    "function_2(y_test,y_predicted)\n",
    "end=time.clock()\n",
    "total_time=end - start\n",
    "print('total time required to RMSE score for one product is :',total_time)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Final Submission_AAIC .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
